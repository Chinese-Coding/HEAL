# 1. 单 GPU 训练
## 1.1 原始命令格式
```bash
python opencood/tools/train.py -y ${CONFIG_FILE} [--model_dir ${CHECKPOINT_FOLDER}]
```

## 1.2 使用到的命令
```bash
# stage1
python opencood/tools/train.py -y None --model_dir opencood/logs/HEAL_m1_based/stage1/m1_base 

# stage2
CUDA_VISIBLE_DEVICES=1 python opencood/tools/train.py -y None --model_dir opencood/logs/HEAL_m1_based/stage2/m2_alignto_m1
python opencood/tools/train.py -y None --model_dir opencood/logs/HEAL_m1_based/stage2/m3_alignto_m1
python opencood/tools/train.py -y None --model_dir opencood/logs/HEAL_m1_based/stage2/m4_alignto_m1
```

# 2. 多 GPU 训练
## 2.1 原始命令格式
```bash
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch  --nproc_per_node=2 --use_env opencood/tools/train_ddp.py -y ${CONFIG_FILE} [--model_dir ${CHECKPOINT_FOLDER}]
```
命令解释 (这部分由 GPT 完成)
* `CUDA_VISIBLE_DEVICES=0,1`: 这个环境变量指定了可见的 GPU 设备。这里指定使用 0 号和 1 号GPU。
* `python -m torch.distributed.launch`: 这个命令使用 `torch.distributed.launch` 模块来启动分布式训练任务
* `--nproc_per_node=2`: 这个参数指定每个节点上的进程数。这里设置为2，意味着将在两个GPU上分别启动一个进程
* `--use_env`: 这个参数告诉启动脚本使用环境变量来初始化分布式配置。
* `opencood/tools/train_ddp.py`: 这是你要运行的Python脚本，用于训练模型。该脚本应该已经被设置为支持分布式训练。
* `-y ${CONFIG_FILE}`: 这个参数传递了配置文件的路径，${CONFIG_FILE}是一个环境变量，代表具体的配置文件路径。-y可能是你的脚本所定义的参数，表示使用该配置文件来进行训练。
* `[--model_dir ${CHECKPOINT_FOLDER}]`: 这个可选参数表示模型的检查点目录，${CHECKPOINT_FOLDER}是一个环境变量，指向模型检查点保存的文件夹路径。--model_dir是传递给训练脚本的参数，用于指定保存或加载模型检查点的目录。

## 2.2 使用到的命令
```bash
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch  --nproc_per_node=2 --use_env opencood/tools/train_ddp.py -y None --model_dir opencood/logs/HEAL_m1_based/stage1/m1_base
```

# 3. TensorBoard

## 3.1 用到的命令
```bash
tensorboard --logdir=opencood/logs/HEAL_m1_based/stage2/m2_alignto_m1 --port=8080 --host=0.0.0.0
```



